{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "attention_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u55JIb6Cvrzb"
      },
      "source": [
        "# Reference - For BAHDANAU METHOD and others as well - https://towardsdatascience.com/attention-seq2seq-with-pytorch-learning-to-invert-a-sequence-34faf4133e53\n",
        "# Reference - For DOT METHOD - https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrIR-y8tdjx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le84f1UPtf7y",
        "outputId": "bea43796-9385-4e7e-ab14-544fcf208759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LobgGm8utqcZ",
        "outputId": "25146cfc-1cae-480a-cc46-02873b65de3e"
      },
      "source": [
        "!ls /content/drive/MyDrive/DLassignment3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi.translit.sampled.train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h1dXW2rtw3j"
      },
      "source": [
        "data = pd.read_csv (\"/content/drive/MyDrive/DLassignment3/hi.translit.sampled.train.tsv\", sep = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W3wPpnKZtyMo",
        "outputId": "342f8630-4c56-41c0-81b6-20aa95921952"
      },
      "source": [
        "data.rename(columns = {'अं' : 'Hindi', 'an' : 'English'}, inplace = True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hindi</th>\n",
              "      <th>English</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अंकगणित</td>\n",
              "      <td>ankganit</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अंकल</td>\n",
              "      <td>uncle</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अंकुर</td>\n",
              "      <td>ankur</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अंकुरण</td>\n",
              "      <td>ankuran</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंकुरित</td>\n",
              "      <td>ankurit</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44198</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>hiuentsang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44199</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>hsuantsang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44200</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>hyensang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44201</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>xuanzang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44202</th>\n",
              "      <td>ॐ</td>\n",
              "      <td>om</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44203 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Hindi     English  3\n",
              "0        अंकगणित    ankganit  3\n",
              "1           अंकल       uncle  4\n",
              "2          अंकुर       ankur  4\n",
              "3         अंकुरण     ankuran  3\n",
              "4        अंकुरित     ankurit  3\n",
              "...          ...         ... ..\n",
              "44198  ह्वेनसांग  hiuentsang  1\n",
              "44199  ह्वेनसांग  hsuantsang  1\n",
              "44200  ह्वेनसांग    hyensang  1\n",
              "44201  ह्वेनसांग    xuanzang  1\n",
              "44202          ॐ          om  3\n",
              "\n",
              "[44203 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWv9r0mItzse",
        "outputId": "732057ac-656d-4541-ae5b-e3cbed2dd59c"
      },
      "source": [
        "  len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y40PYupXt1_C"
      },
      "source": [
        "input_texts=data['English']\n",
        "target_texts=data['Hindi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ItIWWwEt3YA"
      },
      "source": [
        "input_texts=list(input_texts)\n",
        "target_texts=list(target_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHtdLxHZt5A8"
      },
      "source": [
        "alphabets = set()\n",
        "characters = set()\n",
        "alphabets.add(' ')\n",
        "alphabets.add('<sos>')\n",
        "alphabets.add('<eos>')\n",
        "characters.add(' ')\n",
        "characters.add('<sos>')\n",
        "characters.add('<eos>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxltLQjVt6QA",
        "outputId": "bba64131-e8c2-49ec-93e9-16287e55fa8a"
      },
      "source": [
        "i=0\n",
        "for input_text in input_texts:\n",
        "  #print(input_text)\n",
        "  try:\n",
        "    for char in input_text:\n",
        "      if char not in alphabets:\n",
        "        alphabets.add(char)\n",
        "  except:\n",
        "    print(\"********************************************************************************************************************************\")\n",
        "    input_texts.remove(input_text)\n",
        "    target_texts.remove(target_texts[i])\n",
        "  i=i+1;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********************************************************************************************************************************\n",
            "********************************************************************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGtAeSDIt73a"
      },
      "source": [
        "for input_text in target_texts:\n",
        "  #print(input_text)\n",
        "  try:\n",
        "    for char in input_text:\n",
        "      if char not in characters:\n",
        "        characters.add(char)\n",
        "  except:print(input_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C1Znx1vt9t1"
      },
      "source": [
        "# alphabets=['\\t','\\n']\n",
        "# # for i in range(65,91):\n",
        "# #   alphabets.append(chr(i))\n",
        "# for i in range(97,123):\n",
        "#   alphabets.append(chr(i))\n",
        "# alphabets.add(' ')\n",
        "alphabets = sorted(list(alphabets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y8DLD9zt_Ax",
        "outputId": "892cfa70-d2d4-435f-d589-e9b7664f7d68"
      },
      "source": [
        "cnt = 0\n",
        "for val in alphabets:\n",
        "  print(cnt,\" \",val)\n",
        "  cnt+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    \n",
            "1   <eos>\n",
            "2   <sos>\n",
            "3   a\n",
            "4   b\n",
            "5   c\n",
            "6   d\n",
            "7   e\n",
            "8   f\n",
            "9   g\n",
            "10   h\n",
            "11   i\n",
            "12   j\n",
            "13   k\n",
            "14   l\n",
            "15   m\n",
            "16   n\n",
            "17   o\n",
            "18   p\n",
            "19   q\n",
            "20   r\n",
            "21   s\n",
            "22   t\n",
            "23   u\n",
            "24   v\n",
            "25   w\n",
            "26   x\n",
            "27   y\n",
            "28   z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK_W9S26uA1x"
      },
      "source": [
        "# characters=['\\t','\\n']\n",
        "# char_list=[codepoint for codepoint in range(0x0900, 0x0980)]\n",
        "# for i in char_list:\n",
        "#   characters.append(chr(i))\n",
        "# characters.add(' ')\n",
        "characters = sorted(list(characters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5VT3-EFuCbC",
        "outputId": "0fbfe608-1b95-4ac1-a70f-fe104e98deab"
      },
      "source": [
        "cnt = 0\n",
        "for val in characters:\n",
        "  print(cnt,\" \",val)\n",
        "  cnt+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    \n",
            "1   <eos>\n",
            "2   <sos>\n",
            "3   ँ\n",
            "4   ं\n",
            "5   ः\n",
            "6   अ\n",
            "7   आ\n",
            "8   इ\n",
            "9   ई\n",
            "10   उ\n",
            "11   ऊ\n",
            "12   ऋ\n",
            "13   ए\n",
            "14   ऐ\n",
            "15   ऑ\n",
            "16   ओ\n",
            "17   औ\n",
            "18   क\n",
            "19   ख\n",
            "20   ग\n",
            "21   घ\n",
            "22   ङ\n",
            "23   च\n",
            "24   छ\n",
            "25   ज\n",
            "26   झ\n",
            "27   ञ\n",
            "28   ट\n",
            "29   ठ\n",
            "30   ड\n",
            "31   ढ\n",
            "32   ण\n",
            "33   त\n",
            "34   थ\n",
            "35   द\n",
            "36   ध\n",
            "37   न\n",
            "38   प\n",
            "39   फ\n",
            "40   ब\n",
            "41   भ\n",
            "42   म\n",
            "43   य\n",
            "44   र\n",
            "45   ल\n",
            "46   व\n",
            "47   श\n",
            "48   ष\n",
            "49   स\n",
            "50   ह\n",
            "51   ़\n",
            "52   ा\n",
            "53   ि\n",
            "54   ी\n",
            "55   ु\n",
            "56   ू\n",
            "57   ृ\n",
            "58   ॅ\n",
            "59   े\n",
            "60   ै\n",
            "61   ॉ\n",
            "62   ो\n",
            "63   ौ\n",
            "64   ्\n",
            "65   ॐ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vbgl7_RuDzV",
        "outputId": "cd9aa29d-f341-4cd6-f3ee-ed63dc1fc2b5"
      },
      "source": [
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "print(max_encoder_seq_length,\",\",max_decoder_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 , 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeJ6LLi2uI1x",
        "outputId": "c2e5b334-f9d1-4150-fbd0-2f997e2b0888"
      },
      "source": [
        "sample_out=[]\n",
        "sample_in=[]\n",
        "for i in range(len(data)):\n",
        "  word_o=data.iloc[i][0]\n",
        "  word_i=data.iloc[i][1]\n",
        "  #print(\"word\",word)\n",
        "  word_vec_o=np.zeros(20, dtype=int)\n",
        "  word_vec_i=np.zeros(20, dtype=int)\n",
        "  \n",
        "  try:\n",
        "    lo=list(word_o)\n",
        "    x=len(lo)\n",
        "    li=list(word_i)\n",
        "    y=len(li)\n",
        "    #print(\"l\",l)\n",
        "    word_vec_o[0] = 2\n",
        "    cnt = 1\n",
        "    for j in range(0,x):\n",
        "      cnt += 1\n",
        "      #print(\"l[j]\",l[j])\n",
        "      ind=characters.index(lo[j])\n",
        "      word_vec_o[j+1] = ind\n",
        "    word_vec_o[cnt] = 1\n",
        "    \n",
        "    word_vec_i[0] = 2\n",
        "    cnt = 1\n",
        "    for j in range(0,y):\n",
        "      cnt += 1\n",
        "      #print(\"l[j]\",l[j])\n",
        "      ind=alphabets.index(li[j])\n",
        "      word_vec_i[j+1] = ind\n",
        "    word_vec_i[cnt] = 1\n",
        "    sample_out.append(word_vec_o)\n",
        "    sample_in.append(word_vec_i)\n",
        "  except:\n",
        "    print(\"error\");\n",
        "  #print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pceBtmUfuK4I",
        "outputId": "961813a3-8fb9-4fc4-ceec-50d909ec5905"
      },
      "source": [
        "data.iloc[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ankganit'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXbXer_0uNM5",
        "outputId": "3ea6fc51-4dc4-4c4c-b922-8bd7b7efc4cd"
      },
      "source": [
        "sample_in[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  3, 16, 13,  9,  3, 16, 11, 22,  1,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q4F37afLuP4Y",
        "outputId": "a182c1fb-b7d0-490d-cd1e-899c09d1ef3a"
      },
      "source": [
        "data.iloc[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'अंकगणित'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bXehwKpuTqr",
        "outputId": "eb9b2550-66c3-4acb-c133-3c42bd81cbca"
      },
      "source": [
        "sample_out[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  6,  4, 18, 20, 32, 53, 33,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1eKS2HbuU54"
      },
      "source": [
        "tmp_x_train_index = random.sample([i for i in range(np.array(sample_in).shape[0])],math.ceil(np.array(sample_in).shape[0]*0.7))\n",
        "tmp_x_train = []\n",
        "tmp_x_val = []\n",
        "tmp_y_train = []\n",
        "tmp_y_val = []\n",
        "for i in tmp_x_train_index:\n",
        "  tmp_x_train.append(sample_in[i])\n",
        "  tmp_y_train.append(sample_out[i])\n",
        "for i in range(np.array(sample_in).shape[0]):\n",
        "  if i not in tmp_x_train_index:\n",
        "    tmp_x_val.append(sample_in[i])\n",
        "    tmp_y_val.append(sample_out[i])\n",
        "\n",
        "# x_train = np.array(sample_in[:math.ceil(np.array(sample_in).shape[0]*0.7)])\n",
        "# y_train = np.array(sample_out[:math.ceil(np.array(sample_out).shape[0]*0.7)])\n",
        "# x_val = np.array(sample_in[math.ceil(np.array(sample_in).shape[0]*0.7):])\n",
        "# y_val = np.array(sample_out[math.ceil(np.array(sample_out).shape[0]*0.7):])\n",
        "# x_train = np.array(sample_in)\n",
        "# y_train = np.array(sample_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApcxrHFhuW1U",
        "outputId": "f358d922-8337-498c-a013-8c2e38ba39bb"
      },
      "source": [
        "for val in tmp_x_train[0]:\n",
        "  print(alphabets[int(val)],end=\"\")\n",
        "print()\n",
        "for val in tmp_y_train[0]:\n",
        "  print(characters[int(val)],end=\"\")\n",
        "print()\n",
        "for val in tmp_x_val[0]:\n",
        "  print(alphabets[int(val)],end=\"\")\n",
        "print()\n",
        "for val in tmp_y_val[0]:\n",
        "  print(characters[int(val)],end=\"\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos>agantuk<eos>           \n",
            "<sos>आगंतुक<eos>            \n",
            "<sos>ankganit<eos>          \n",
            "<sos>अंकगणित<eos>           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSkFn64puaAj"
      },
      "source": [
        "# x_train = np.array(tmp_x_train)\n",
        "# y_train = np.array(tmp_y_train)\n",
        "# x_val = np.array(tmp_x_val)\n",
        "# y_val = np.array(tmp_y_val)\n",
        "x_train = tmp_x_train\n",
        "y_train = tmp_y_train\n",
        "x_val = tmp_x_val\n",
        "y_val = tmp_y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzc8sYSxubcj",
        "outputId": "0a029b2e-729e-452d-e583-1f94377e4591"
      },
      "source": [
        "torch.tensor(x_train[32*0:32*1][:]).T.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxtR6kTKCSZY"
      },
      "source": [
        "emb_size = 300\n",
        "hid_size = 128\n",
        "n_layer = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXQhNG9Puf0n"
      },
      "source": [
        "**ENCODER MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k430-_ZDueYE",
        "outputId": "bd074758-8c43-4d6c-cba7-39f14737d89a"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "    \n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(self.hidden_size, self.hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "    # print(\"EncoderModel:input :\",x.unsqueeze(0).shape)\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (20, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    outputs = embedding\n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(outputs, (hidden_state, cell_state))\n",
        "\n",
        "    return outputs, hidden_state, cell_state\n",
        "\n",
        "input_size_encoder = len(alphabets)\n",
        "encoder_embedding_size = emb_size\n",
        "hidden_size = hid_size\n",
        "num_layers = n_layer\n",
        "encoder_dropout = float(0.5)\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout)\n",
        "print(encoder_lstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(29, 128)\n",
            "  (LSTM): LSTM(128, 128, dropout=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNs9FVUcyefL"
      },
      "source": [
        "**ATTENTION DECODER LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3nlP83wAJdb"
      },
      "source": [
        "**DOT METHOD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFedgNf3xWVZ",
        "outputId": "66c9b6a5-e7f8-44b3-d031-6cfb34034ec5"
      },
      "source": [
        "# DOT METHOD\n",
        "class AttentionDecoderLSTM_dot(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, max_length, num_layers, p, output_size):\n",
        "    super(AttentionDecoderLSTM_dot, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Max length??? --> Can be considered as max timesteps used?\n",
        "    self.max_length = max_length\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Softmax Function\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    # ReLU Function\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "\n",
        "    # attn -> Previous Hidden + Current Embedding\n",
        "    # self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
        "    self.attn = nn.Linear(self.hidden_size*3, self.max_length)\n",
        "\n",
        "    # attn_combine -> bmm(Encoder outputs, softmax(attn))\n",
        "    self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(self.hidden_size, self.hidden_size, self.num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state, encoder_outputs):\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "    print(\"DecoderModel:Input :\",x.shape)\n",
        "    print(\"DecoderModel:Hidden state :\",hidden_state.shape)\n",
        "    print(\"DecoderModel:Cell state :\",cell_state.shape)\n",
        "    print(\"DecoderModel:Encoder Output :\",encoder_outputs.shape)\n",
        "\n",
        "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    print(\"DecoderModel:embedding :\",embedding.shape)\n",
        "\n",
        "    concat_emb_state = torch.cat( (embedding[0], hidden_state[0], cell_state[0]),1) # dim = 1 --> inner most vectors are concatinated i.e. (1,32,256)X(1,32,256)X(1,32,256) = (32X768)\n",
        "    print(\"DecoderModel:concat embedding + state :\",concat_emb_state.shape)\n",
        "\n",
        "    attn_e_s = self.attn(concat_emb_state) # (32 X 768) X (768 X 20)\n",
        "    print(\"DecoderModel:attn embedding + state :\",attn_e_s.shape)\n",
        "\n",
        "    attn_weights = self.softmax(attn_e_s) # (32 x 20)\n",
        "    print(\"DecoderModel:attn_weights :\",attn_weights.shape) \n",
        "\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs) # (32x1x20) x (32x20x256) = (32x1x256)\n",
        "    print(\"DecoderModel:attn_applied :\",attn_applied.shape)\n",
        "\n",
        "    # print(attn_applied[0][0].shape)\n",
        "    attn_applied_f = torch.zeros(attn_applied.shape[0], attn_applied.shape[2]) # Need to convert (32x1x256) to (32x256)\n",
        "    print(attn_applied_f.shape)\n",
        "\n",
        "    for i in range(attn_applied.shape[0]):\n",
        "      attn_applied_f[i] = attn_applied[i][0]\n",
        "\n",
        "    emb_attn_cat = torch.cat((embedding[0], attn_applied_f.unsqueeze(0)[0]), 1) # concat (1x32x256) and (1x32x256) with dim=1 --> (32x512)\n",
        "    print(\"DecoderModel:(Embedding + attn_applied) :\",emb_attn_cat.shape)\n",
        "\n",
        "    attn_combine = self.attn_combine(emb_attn_cat).unsqueeze(0) # (1x32x512) --> (1x32x256)\n",
        "    print(\"DecoderModel:attn_combine :\",attn_combine.shape)\n",
        "\n",
        "    outputs = self.relu(attn_combine)\n",
        "\n",
        "    # Shape --> outputs (1, 32, 256) [1, batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 256) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(outputs, (hidden_state, cell_state))\n",
        "\n",
        "\n",
        "    # Shape --> predictions (1, 32, 66) [ 1, batch_size , output_size]\n",
        "    predictions = self.softmax(self.fc(outputs))\n",
        "    print(\"DecoderModel:Predictions : \",predictions.shape)\n",
        "\n",
        "    # Shape --> predictions (32, 66) [batch_size , output_size]\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(characters)\n",
        "decoder_embedding_size = emb_size\n",
        "hidden_size = hid_size\n",
        "num_layers = n_layer\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = len(characters)\n",
        "max_length = 20\n",
        "\n",
        "decoder_lstm_dot = AttentionDecoderLSTM_dot(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, max_length, num_layers, decoder_dropout, output_size)\n",
        "print(decoder_lstm_dot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AttentionDecoderLSTM_dot(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (relu): ReLU()\n",
            "  (embedding): Embedding(66, 128)\n",
            "  (attn): Linear(in_features=384, out_features=20, bias=True)\n",
            "  (attn_combine): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (LSTM): LSTM(128, 128, dropout=0.5)\n",
            "  (fc): Linear(in_features=128, out_features=66, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl4qk6Zs_8Wd"
      },
      "source": [
        "**BAHDANAU METHOD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR0uvlYl08de",
        "outputId": "5575868f-8155-48a9-faa8-d27be8ccec06"
      },
      "source": [
        "# BAHDANAU METHOD\n",
        "class AttentionDecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, max_length, num_layers, p, output_size):\n",
        "    super(AttentionDecoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # self.batch_size = batch_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Max length??? --> Can be considered as max timesteps used?\n",
        "    self.max_length = max_length\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Softmax Function\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    # Tanh Function\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "    # Weighted encoder_output and hidden layer (W*hid_l + U*enc_out)\n",
        "    self.Wa = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "    self.Ua = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "\n",
        "    # while doing bmm with weighted out\n",
        "    # self.va = nn.Parameter(torch.FloatTensor(self.batch_size, self.hidden_size))\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM_1 = nn.LSTM(self.hidden_size, self.hidden_size, self.num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state, encoder_outputs,batch_size):\n",
        "    # self.batch_size = batch_size\n",
        "    # self.va = nn.Parameter(torch.FloatTensor(self.batch_size, self.hidden_size))\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "    # print(\"DecoderModel:Input :\",x.shape)\n",
        "    # print(\"DecoderModel:Hidden state :\",hidden_state.shape)\n",
        "    # print(\"DecoderModel:Cell state :\",cell_state.shape)\n",
        "    # print(\"DecoderModel:Encoder Output :\",encoder_outputs.shape)\n",
        "\n",
        "    # Shape -----------> (1, 32, 256) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # print(\"DecoderModel:embedding :\",embedding.shape)\n",
        "\n",
        "\n",
        "    # Shape ----> output, hidden, cell ---> (1,32,256)\n",
        "    L, (hidden_state, cell_state) = self.LSTM_1(embedding, (hidden_state, cell_state))\n",
        "    # print(\"DecoderModel:lstm_1:outputs :\",L.shape)\n",
        "    # print(\"DecoderModel:lstm_1:hidden :\",hidden_state.shape)\n",
        "    # print(\"DecoderModel:lstm_1:cell :\",cell_state.shape)\n",
        "\n",
        "    L = L.squeeze(0).unsqueeze(1) # Shape --> (32,1,256)\n",
        "    # print(\"DecoderModel:lstm_1:outputs :\",L.shape)\n",
        "\n",
        "    # tanh(W*hidden_layer + U*encoder_output) --> (32,20,256)\n",
        "    # hidden_layer --> (32,1,256)\n",
        "    # encoder_output --> (32,20,256)\n",
        "    out = self.tanh(self.Wa(L) + self.Ua(encoder_outputs))\n",
        "    # print(\"DecoderModel:weighted out :\",out.shape)\n",
        "\n",
        "    # (32x20x256) x (32x256x1) ---> (32x20x1) --> (32x20)\n",
        "    wts = torch.bmm(out, nn.Parameter(torch.FloatTensor(batch_size, self.hidden_size)).unsqueeze(2)).squeeze(-1)\n",
        "    wts = F.softmax(wts, dim=-1)\n",
        "    # print(\"DecoderModel:weights :\",wts.shape)\n",
        "\n",
        "    # Weighted sum of encoder outputs (32x1x20) x (32x20x256) --> (32x1x256) --> (32x256)\n",
        "    context = torch.bmm(wts.unsqueeze(1), encoder_outputs).squeeze(1)\n",
        "    # print(\"DecoderModel:context :\",context.shape)\n",
        "\n",
        "    # Linearize context and attn_comb(Embedding, Previous hidden layer)\n",
        "    # step 1 : (32x256) + (32x256) --> (32x512)\n",
        "    # step 2 : (32x512) --> (32x256)\n",
        "    predictions = self.softmax(self.fc(torch.cat((L.squeeze(1), context),1)))\n",
        "    # print(\"DecoderModel:Predictions : \",predictions.shape)\n",
        "\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(characters)\n",
        "decoder_embedding_size = emb_size\n",
        "hidden_size = hid_size\n",
        "num_layers = n_layer\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = len(characters)\n",
        "max_length = 20\n",
        "\n",
        "decoder_lstm = AttentionDecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, max_length, num_layers, decoder_dropout, output_size)\n",
        "print(decoder_lstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AttentionDecoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (tanh): Tanh()\n",
            "  (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
            "  (Ua): Linear(in_features=128, out_features=128, bias=False)\n",
            "  (embedding): Embedding(66, 128)\n",
            "  (LSTM_1): LSTM(128, 128, dropout=0.5)\n",
            "  (fc): Linear(in_features=256, out_features=66, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39oeVcpT8QGc"
      },
      "source": [
        "**ATTENTION Seq2Seq**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXvjPi7Z8Yu1",
        "outputId": "d066ca31-70d5-426c-a85f-cde71c8456df"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target,num_layers, hidden_size,max_length = 20, tfr=0.5):\n",
        "    # Shape - Source : (20, 32) [(Sentence length German + some padding), Number of Sentences]\n",
        "    batch_size = source.shape[1]\n",
        "\n",
        "    # Shape - Source : (20, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(characters)\n",
        "    \n",
        "    # Shape --> outputs (20, 32, 66) \n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
        "    # print(\"Model:Output : \",outputs.shape)\n",
        "\n",
        "    temp_encoder_outputs = torch.zeros(max_length, batch_size, hidden_size)\n",
        "    # print(\"Model:Temp Encoder_outputs\",temp_encoder_outputs.shape)\n",
        "\n",
        "    encoder_outputs = torch.zeros(batch_size,max_length, hidden_size)\n",
        "    # print(\"Model:Encoder_outputs\",encoder_outputs.shape)\n",
        "\n",
        "    hidden_state_encoder = torch.zeros(num_layers, batch_size, hidden_size) # 1 X 32 X 256\n",
        "    cell_state_encoder = torch.zeros(num_layers, batch_size, hidden_size) # 1 X 32 X 256\n",
        "    # print(\"Model:InitStateLayer : \",hidden_state_encoder.shape,cell_state_encoder.shape)\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 256) ,(2, 32, 256) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "    for ei in range(target_len):\n",
        "        encoder_output, hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source[ei], hidden_state_encoder, cell_state_encoder)\n",
        "        temp_encoder_outputs[ei] = encoder_output[0]\n",
        "        # print(ei,\" Model:Encoder Outputs and states :\")\n",
        "        # print(encoder_output.shape)\n",
        "        # print(hidden_state_encoder.shape)\n",
        "        # print(cell_state_encoder.shape)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      for j in range(max_length):\n",
        "        encoder_outputs[i][j] = temp_encoder_outputs[j][i]\n",
        "    \n",
        "    # hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
        "\n",
        "    # Shape of x (32 elements)\n",
        "    x = target[0] # Trigger token <SOS>\n",
        "    # print(\"Model:Target : \", x.shape)\n",
        "\n",
        "    for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766) \n",
        "      output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder, encoder_outputs,batch_size)\n",
        "      # print(ei,\" Model:Decoder Outputs and states :\")\n",
        "      # print(output.shape)\n",
        "      # print(hidden_state_decoder.shape)\n",
        "      # print(cell_state_decoder.shape)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    return outputs\n",
        "\n",
        "model_lstm = Seq2Seq(encoder_lstm,decoder_lstm)\n",
        "print(model_lstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (Encoder_LSTM): EncoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(29, 128)\n",
            "    (LSTM): LSTM(128, 128, dropout=0.5)\n",
            "  )\n",
            "  (Decoder_LSTM): AttentionDecoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (softmax): Softmax(dim=1)\n",
            "    (tanh): Tanh()\n",
            "    (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (Ua): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (embedding): Embedding(66, 128)\n",
            "    (LSTM_1): LSTM(128, 128, dropout=0.5)\n",
            "    (fc): Linear(in_features=256, out_features=66, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtYZUtLta_pL",
        "outputId": "2bf007e2-0d8a-435f-b6fc-d4a153cbfc57"
      },
      "source": [
        "torch.zeros(32,20).T.unsqueeze(1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 1, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08tUjAwmkrGO"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_lstm.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5hj4ZKIBxfV",
        "outputId": "2ca0ab96-2804-4f53-c1df-6a965d8a63f0"
      },
      "source": [
        "print(torch.tensor(x_train).shape[0])\n",
        "print(math.floor(torch.tensor(x_train).shape[0]/32))\n",
        "print(math.floor(torch.tensor(x_train).shape[0]/32)*32)\n",
        "\n",
        "num_of_batches = math.floor(torch.tensor(x_train).shape[0]/32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30938\n",
            "966\n",
            "30912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFUI4bqktQo"
      },
      "source": [
        "def translate_word(model, word_e,word_h,num_layers,max_length=20):    \n",
        "    # for val in word_e:\n",
        "    #   print(val, end=\", \")\n",
        "    # print()\n",
        "    # for val in word_h:\n",
        "    #   print(val, end=\", \")\n",
        "    print()\n",
        "    print(\"Input word : \")\n",
        "    for val in word_e:\n",
        "      print(alphabets[val], end=\"\")\n",
        "    print()\n",
        "    print(\"Expected word : \")\n",
        "    for val in word_h:\n",
        "      print(characters[val], end=\"\")\n",
        "    print()\n",
        "    # print(torch.tensor(word_e).unsqueeze(1).shape)\n",
        "    # print(torch.tensor(word_h).unsqueeze(1).shape)\n",
        "\n",
        "    temp_encoder_outputs = torch.zeros(max_length, 1, hidden_size)\n",
        "    # print(\"Model:Temp Encoder_outputs\",temp_encoder_outputs.shape)\n",
        "\n",
        "    encoder_outputs = torch.zeros(1,max_length, hidden_size)\n",
        "    # print(\"Model:Encoder_outputs\",encoder_outputs.shape)\n",
        "\n",
        "    hidden = torch.zeros(num_layers, 1, hidden_size) # 1 X 32 X 256\n",
        "    cell = torch.zeros(num_layers, 1, hidden_size) # 1 X 32 X 256\n",
        "    # Build encoder hidden, cell state\n",
        "    # print(1)\n",
        "    # print(torch.tensor([word_e[0]]).shape)\n",
        "    with torch.no_grad():\n",
        "      for ei in range(max_length):\n",
        "        encoder_output, hidden, cell = model.Encoder_LSTM(torch.tensor([word_e[ei]]), hidden, cell)\n",
        "        temp_encoder_outputs[ei] = encoder_output[0]\n",
        "    # print(2)\n",
        "    for j in range(max_length):\n",
        "      encoder_outputs[0][j] = temp_encoder_outputs[j][0]\n",
        "    # print(3)\n",
        "    outputs = [2]\n",
        "    for i in range(max_length):\n",
        "        previous_word = torch.tensor([outputs[-1]])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell, encoder_outputs,1)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "        # print(output.argmax(1).item())\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == 1:\n",
        "            break\n",
        "    # print(4)\n",
        "    result = ''\n",
        "    for val in outputs:\n",
        "      result += characters[val]\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-kvhWAqkvEK"
      },
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwkRfd-nkw0d"
      },
      "source": [
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfJM3UGmk1gA",
        "outputId": "3787d16a-a405-4ac6-8549-d9b2a56b18ee"
      },
      "source": [
        "# MAKE CHANGES\n",
        "epoch_loss = 0.0\n",
        "num_epochs = 10\n",
        "best_loss = 999999\n",
        "best_epoch = -1\n",
        "sentence1 = \"ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster\"\n",
        "ts1 = []\n",
        "\n",
        "# torch.tensor(x_train[32*0:32*1][:]).T.shape ----> torch.Size([20, 32])\n",
        "\n",
        "# num_of_batches = 100\n",
        "step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model_lstm.eval()\n",
        "  translated_word1 = translate_word(model_lstm, x_train[0], y_train[0],num_layers)\n",
        "  print(f\"Translated word : \\n {translated_word1}\")\n",
        "  ts1.append(translated_word1)\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "\n",
        "  model_lstm.train(True)\n",
        "  # Number of set of batch sizes\n",
        "  # for batch_idx, batch in enumerate(train_iterator):\n",
        "  for batch in range(num_of_batches):\n",
        "    print(\"Batch : \",batch, end='\\r')\n",
        "    input = torch.tensor(x_train[32*batch:32*(batch+1)][:]).T # of size 20 X 32 (32 -> batch size, 20 -> 1 word max letters)\n",
        "    target = torch.tensor(y_train[32*batch:32*(batch+1)][:]).T # of size 20 X 32\n",
        "    # print(input.T.shape)\n",
        "    # print(target.T.shape)\n",
        "\n",
        "    # input = batch.src.to(device) \n",
        "    # target = batch.trg.to(device) \n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model_lstm(input, target,num_layers,128)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    # output = output[:output.shape[0]-1].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear the accumulating gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Calculate the loss value for every epoch\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Calculate the gradients for weights & biases using back-propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the gradient value is it exceeds > 1\n",
        "    torch.nn.utils.clip_grad_norm_(model_lstm.parameters(), max_norm=1)\n",
        "\n",
        "    # Update the weights values using the gradients we calculated using bp \n",
        "    optimizer.step()\n",
        "    # step += 1\n",
        "    # epoch_loss += loss.item()\n",
        "    # writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    best_epoch = epoch\n",
        "    save_checkpoint(dict({'model':model_lstm, 'best_loss':best_loss, 'epoch':epoch, 'optimizer':optimizer, 'epoch_loss':epoch_loss}))\n",
        "    if ((epoch - best_epoch) >= 10):\n",
        "      print(\"no improvement in 10 epochs, break\")\n",
        "      break\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "  \n",
        "print(epoch_loss)\n",
        "\n",
        "# score = bleu(test_data[1:100], model, german, english, device)\n",
        "# print(f\"Bleu score {score*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 1 / 10\n",
            "=> Saving checkpoint\n",
            "Epoch_Loss - 3.5987019538879395\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 2 / 10\n",
            "Epoch_Loss - 3.598663330078125\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 3 / 10\n",
            "Epoch_Loss - 3.5986709594726562\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 4 / 10\n",
            "Epoch_Loss - 3.598649740219116\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 5 / 10\n",
            "Epoch_Loss - 3.598666191101074\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 6 / 10\n",
            "Epoch_Loss - 3.59867262840271\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 7 / 10\n",
            "Epoch_Loss - 3.5986292362213135\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 8 / 10\n",
            "Epoch_Loss - 3.5986287593841553\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 9 / 10\n",
            "Epoch_Loss - 3.598644971847534\n",
            "\n",
            "\n",
            "Input word : \n",
            "<sos>agantuk<eos>           \n",
            "Expected word : \n",
            "<sos>आगंतुक<eos>            \n",
            "Translated word : \n",
            " <sos>                    \n",
            "Epoch - 10 / 10\n",
            "Epoch_Loss - 3.5986106395721436\n",
            "\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui-l8hXMBnxN"
      },
      "source": [
        "**GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhq9-PbmO-zg"
      },
      "source": [
        "class EncoderGRU(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderGRU, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "    \n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.GRU = nn.GRU(self.hidden_size, self.hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "  def forward(self, x, hidden_state):\n",
        "    # print(\"EncoderModel:input :\",x.unsqueeze(0).shape)\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (20, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    outputs = embedding\n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "    outputs, hidden_state = self.GRU(outputs, hidden_state)\n",
        "\n",
        "    return outputs, hidden_state\n",
        "\n",
        "input_size_encoder = len(alphabets)\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "encoder_dropout = float(0.5)\n",
        "\n",
        "encoder_gru = EncoderGRU(input_size_encoder, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout)\n",
        "print(encoder_gru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38BhMcKUPe_C"
      },
      "source": [
        "# BAHDANAU METHOD\n",
        "class AttentionDecoderGRU(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, max_length, num_layers, p, output_size):\n",
        "    super(AttentionDecoderGRU, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # self.batch_size = batch_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Max length??? --> Can be considered as max timesteps used?\n",
        "    self.max_length = max_length\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Softmax Function\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    # Tanh Function\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "    # Weighted encoder_output and hidden layer (W*hid_l + U*enc_out)\n",
        "    self.Wa = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "    self.Ua = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "\n",
        "    # while doing bmm with weighted out\n",
        "    # self.va = nn.Parameter(torch.FloatTensor(self.batch_size, self.hidden_size))\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.GRU = nn.GRU(self.hidden_size, self.hidden_size, self.num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, encoder_outputs,batch_size):\n",
        "    # self.batch_size = batch_size\n",
        "    # self.va = nn.Parameter(torch.FloatTensor(self.batch_size, self.hidden_size))\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "    # print(\"DecoderModel:Input :\",x.shape)\n",
        "    # print(\"DecoderModel:Hidden state :\",hidden_state.shape)\n",
        "    # print(\"DecoderModel:Cell state :\",cell_state.shape)\n",
        "    # print(\"DecoderModel:Encoder Output :\",encoder_outputs.shape)\n",
        "\n",
        "    # Shape -----------> (1, 32, 256) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # print(\"DecoderModel:embedding :\",embedding.shape)\n",
        "\n",
        "\n",
        "    # Shape ----> output, hidden, cell ---> (1,32,256)\n",
        "    L, hidden_state = self.GRU(embedding, hidden_state)\n",
        "    # print(\"DecoderModel:lstm_1:outputs :\",L.shape)\n",
        "    # print(\"DecoderModel:lstm_1:hidden :\",hidden_state.shape)\n",
        "    # print(\"DecoderModel:lstm_1:cell :\",cell_state.shape)\n",
        "\n",
        "    L = L.squeeze(0).unsqueeze(1) # Shape --> (32,1,256)\n",
        "    # print(\"DecoderModel:lstm_1:outputs :\",L.shape)\n",
        "\n",
        "    # tanh(W*hidden_layer + U*encoder_output) --> (32,20,256)\n",
        "    # hidden_layer --> (32,1,256)\n",
        "    # encoder_output --> (32,20,256)\n",
        "    out = self.tanh(self.Wa(L) + self.Ua(encoder_outputs))\n",
        "    # print(\"DecoderModel:weighted out :\",out.shape)\n",
        "\n",
        "    # (32x20x256) x (32x256x1) ---> (32x20x1) --> (32x20)\n",
        "    wts = torch.bmm(out, nn.Parameter(torch.FloatTensor(batch_size, self.hidden_size)).unsqueeze(2)).squeeze(-1)\n",
        "    # print(\"DecoderModel:weights :\",wts.shape)\n",
        "\n",
        "    # Weighted sum of encoder outputs (32x1x20) x (32x20x256) --> (32x1x256) --> (32x256)\n",
        "    context = torch.bmm(wts.unsqueeze(1), encoder_outputs).squeeze(1)\n",
        "    # print(\"DecoderModel:context :\",context.shape)\n",
        "\n",
        "    # Linearize context and attn_comb(Embedding, Previous hidden layer)\n",
        "    # step 1 : (32x256) + (32x256) --> (32x512)\n",
        "    # step 2 : (32x512) --> (32x256)\n",
        "    predictions = self.softmax(self.fc(torch.cat((L.squeeze(1), context),1)))\n",
        "    # print(\"DecoderModel:Predictions : \",predictions.shape)\n",
        "\n",
        "    return predictions, hidden_state\n",
        "\n",
        "input_size_decoder = len(characters)\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = len(characters)\n",
        "max_length = 20\n",
        "\n",
        "decoder_gru = AttentionDecoderGRU(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, max_length, num_layers, decoder_dropout, output_size)\n",
        "print(decoder_gru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ_qilJQP9af"
      },
      "source": [
        "class Seq2SeqGRU(nn.Module):\n",
        "  def __init__(self, Encoder_GRU, Decoder_GRU):\n",
        "    super(Seq2SeqGRU, self).__init__()\n",
        "    self.Encoder_GRU = Encoder_GRU\n",
        "    self.Decoder_GRU = Decoder_GRU\n",
        "\n",
        "  def forward(self, source, target, num_layers,hidden_size,max_length = 20, tfr=0.5):\n",
        "    # Shape - Source : (20, 32) [(Sentence length German + some padding), Number of Sentences]\n",
        "    batch_size = source.shape[1]\n",
        "\n",
        "    # Shape - Source : (20, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(characters)\n",
        "    \n",
        "    # Shape --> outputs (20, 32, 66) \n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
        "    # print(\"Model:Output : \",outputs.shape)\n",
        "\n",
        "    temp_encoder_outputs = torch.zeros(max_length, batch_size, hidden_size)\n",
        "    # print(\"Model:Temp Encoder_outputs\",temp_encoder_outputs.shape)\n",
        "\n",
        "    encoder_outputs = torch.zeros(batch_size,max_length, hidden_size)\n",
        "    # print(\"Model:Encoder_outputs\",encoder_outputs.shape)\n",
        "\n",
        "    hidden_state_encoder = torch.zeros(num_layers, batch_size, hidden_size) # 1 X 32 X 256\n",
        "    # print(\"Model:InitStateLayer : \",hidden_state_encoder.shape,cell_state_encoder.shape)\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 256) ,(2, 32, 256) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "    for ei in range(target_len):\n",
        "        encoder_output, hidden_state_encoder = self.Encoder_GRU(source[ei], hidden_state_encoder)\n",
        "        temp_encoder_outputs[ei] = encoder_output[0]\n",
        "        # print(ei,\" Model:Encoder Outputs and states :\")\n",
        "        # print(encoder_output.shape)\n",
        "        # print(hidden_state_encoder.shape)\n",
        "        # print(cell_state_encoder.shape)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      for j in range(max_length):\n",
        "        encoder_outputs[i][j] = temp_encoder_outputs[j][i]\n",
        "    \n",
        "    # hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
        "\n",
        "    # Shape of x (32 elements)\n",
        "    x = target[0] # Trigger token <SOS>\n",
        "    # print(\"Model:Target : \", x.shape)\n",
        "\n",
        "    for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766) \n",
        "      output, hidden_state_decoder = self.Decoder_GRU(x, hidden_state_encoder, encoder_outputs,batch_size)\n",
        "      # print(ei,\" Model:Decoder Outputs and states :\")\n",
        "      # print(output.shape)\n",
        "      # print(hidden_state_decoder.shape)\n",
        "      # print(cell_state_decoder.shape)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    return outputs\n",
        "\n",
        "model_gru = Seq2SeqGRU(encoder_gru,decoder_gru)\n",
        "print(model_gru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wfPiIpSBcJG"
      },
      "source": [
        "# epoch_loss = 0.0\n",
        "# num_epochs = 20\n",
        "# best_loss = 999999\n",
        "# best_epoch = -1\n",
        "# for batch in range(num_of_batches):\n",
        "#   input = torch.tensor(x_train[32*batch:32*(batch+1)][:]).T # of size 20 X 32 (32 -> batch size, 20 -> 1 word max letters)\n",
        "#   target = torch.tensor(y_train[32*batch:32*(batch+1)][:]).T # of size 20 X 32\n",
        "#   output = model_lstm(input, target,1,128)\n",
        "#   # print(output.shape[0]-1)\n",
        "#   output = output[:output.shape[0]-1].reshape(-1, output.shape[2])\n",
        "#   target = target[1:].reshape(-1)\n",
        "#   # print(output.shape, target.shape)\n",
        "\n",
        "#   # Clear the accumulating gradients\n",
        "#   optimizer.zero_grad()\n",
        "#   # Calculate the loss value for every epoch\n",
        "#   loss = criterion(output, target)\n",
        "\n",
        "#   # Calculate the gradients for weights & biases using back-propagation\n",
        "#   loss.backward()\n",
        "#   # Clip the gradient value is it exceeds > 1\n",
        "#   torch.nn.utils.clip_grad_norm_(model_lstm.parameters(), max_norm=1)\n",
        "#   # Update the weights values using the gradients we calculated using bp \n",
        "#   optimizer.step()\n",
        "#   # step += 1\n",
        "#   # epoch_loss += loss.item()\n",
        "#   # writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "# if epoch_loss < best_loss:\n",
        "#   best_loss = epoch_loss\n",
        "#   # best_epoch = epoch\n",
        "#   # save_checkpoint(dict({'model':model, 'best_loss':best_loss, 'epoch':epoch, 'optimizer':optimizer, 'epoch_loss':epoch_loss}))\n",
        "#   # if ((epoch - best_epoch) >= 10):\n",
        "#     # print(\"no improvement in 10 epochs, break\")\n",
        "# print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "# print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km_fbmCDkzhQ"
      },
      "source": [
        "# result = translate_word(model_lstm, x_train[0], y_train[0],1)\n",
        "# print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}