{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_EngToHindi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db4a6d72dc0449df9f66d9626b44d8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a29ee2f4e884222a45c2e4a85d88d82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29ddde6b6cc84fbd86f773ca360c7e1b",
              "IPY_MODEL_a0794163c0ba4a32b451c3856b2d4b02"
            ]
          }
        },
        "2a29ee2f4e884222a45c2e4a85d88d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29ddde6b6cc84fbd86f773ca360c7e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_177a1addc5a2420d8a1f89c87e592bf0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10ff7cf84c3345f79ef443d7408822f2"
          }
        },
        "a0794163c0ba4a32b451c3856b2d4b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1b7e00b772e456c9ffb8f3214ff67a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89e2e6a117004e719048d1706764abc3"
          }
        },
        "177a1addc5a2420d8a1f89c87e592bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10ff7cf84c3345f79ef443d7408822f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1b7e00b772e456c9ffb8f3214ff67a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89e2e6a117004e719048d1706764abc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGUzAjIutrIq",
        "outputId": "2c8715c5-ba66-4be2-d38a-f8503214f624"
      },
      "source": [
        "  ! pip install wandb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Using cached https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Using cached https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Using cached https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=7eb3e5638486f0f447f5a691b851582166c5ff22e57c43a67504614264de8e16\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=905dff1224e5fd381ce46d0c3ae30976ff0f860c9d0b0eaaac084fb612873c5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: sentry-sdk, configparser, pathtools, subprocess32, smmap, gitdb, GitPython, shortuuid, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2zI50UCt9iq"
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDiou8-duFuX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from keras import Input, regularizers, Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r512JZakuAco",
        "outputId": "c59fd50e-4c15-49ee-cb04-7be30cf7009a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAlptuueuM2u"
      },
      "source": [
        "data = pd.read_csv (\"/content/drive/MyDrive/DLassignment3/hi.translit.sampled.train.tsv\", sep = '\\t')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LirBEof1uO3_",
        "outputId": "82c85923-aa1e-48a6-b803-dd12c35e8746"
      },
      "source": [
        "data.rename(columns = {'अं' : 'Hindi', 'an' : 'English'}, inplace = True)\n",
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hindi</th>\n",
              "      <th>English</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अंकगणित</td>\n",
              "      <td>ankganit</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अंकल</td>\n",
              "      <td>uncle</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अंकुर</td>\n",
              "      <td>ankur</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अंकुरण</td>\n",
              "      <td>ankuran</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंकुरित</td>\n",
              "      <td>ankurit</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44198</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>hiuentsang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44199</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>hsuantsang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44200</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>hyensang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44201</th>\n",
              "      <td>ह्वेनसांग</td>\n",
              "      <td>xuanzang</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44202</th>\n",
              "      <td>ॐ</td>\n",
              "      <td>om</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44203 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Hindi     English  3\n",
              "0        अंकगणित    ankganit  3\n",
              "1           अंकल       uncle  4\n",
              "2          अंकुर       ankur  4\n",
              "3         अंकुरण     ankuran  3\n",
              "4        अंकुरित     ankurit  3\n",
              "...          ...         ... ..\n",
              "44198  ह्वेनसांग  hiuentsang  1\n",
              "44199  ह्वेनसांग  hsuantsang  1\n",
              "44200  ह्वेनसांग    hyensang  1\n",
              "44201  ह्वेनसांग    xuanzang  1\n",
              "44202          ॐ          om  3\n",
              "\n",
              "[44203 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNu9EjGzPAY0",
        "outputId": "a040de1c-d1ae-480e-8f9f-ed5c26fea250"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for j in range(len(data)):\n",
        "  try:\n",
        "    input_text=data.iloc[j,1]\n",
        "    target_text=data.iloc[j,0]\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    if(len(input_text)>=1 and len(target_text)>=2):\n",
        "      input_texts.append(input_text)\n",
        "      target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "      if char not in input_characters:\n",
        "        input_characters.add(char)\n",
        "    for char in target_text:\n",
        "      if char not in target_characters:\n",
        "        target_characters.add(char)\n",
        "  except: print(\"error\")\n",
        "input_characters.add(' ')\n",
        "target_characters.add(' ')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error\n",
            "error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1TgBHvXPZQW",
        "outputId": "79c0a4e7-a622-4d07-c0c4-f593c7df6db7"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 44201\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRPfbkxuneL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f88c634-8bdc-4aac-be34-03c93c22ac25"
      },
      "source": [
        "  tmp_x_train = []\n",
        "  tmp_x_train_index = random.sample([i for i in range(0,np.array(input_texts).shape[0])],math.ceil(np.array(input_texts).shape[0]*0.7))\n",
        "  tmp_x_val = []\n",
        "  tmp_y_train = []\n",
        "  tmp_y_val = []\n",
        "  for i in tmp_x_train_index:\n",
        "    tmp_x_train.append(input_texts[i])\n",
        "    tmp_y_train.append(target_texts[i])\n",
        "  for i in range(np.array(input_texts).shape[0]):\n",
        "    if i not in tmp_x_train_index:\n",
        "      tmp_x_val.append(input_texts[i])\n",
        "      tmp_y_val.append(target_texts[i])\n",
        "  for val in tmp_x_train[0]:\n",
        "    print(input_characters[np.argmax(np.array(val))],end=\"\")\n",
        "  print()\n",
        "  for val in tmp_y_train[0]:\n",
        "    print(target_characters[np.argmax(np.array(val))],end=\"\")\n",
        "  print()\n",
        "  for val in tmp_x_val[0]:\n",
        "    print(input_characters[np.argmax(val)],end=\"\")\n",
        "  print()\n",
        "  for val in tmp_y_val[0]:\n",
        "    print(target_characters[np.argmax(val)],end=\"\")\n",
        "  print()\n",
        "  lim=int(len(tmp_x_train)*0.9)\n",
        "  x_train = tmp_x_train[0:lim]\n",
        "  y_train = tmp_y_train[0:lim]\n",
        "  x_val = tmp_x_train[lim:]\n",
        "  y_val = tmp_y_train[lim:]\n",
        "  x_test = tmp_x_val\n",
        "  y_test = tmp_y_val\n",
        "\n",
        "  # x_train = np.array(sample_in[:math.ceil(np.array(sample_in).shape[0]*0.7)])\n",
        "  # y_train = np.array(sample_out[:math.ceil(np.array(sample_out).shape[0]*0.7)])\n",
        "  # x_val = np.array(sample_in[math.ceil(np.array(sample_in).shape[0]*0.7):])\n",
        "  # y_val = np.array(sample_out[math.ceil(np.array(sample_out).shape[0]*0.7):])\n",
        "  # x_train = np.array(sample_in)\n",
        "  # y_train = np.array(sample_out)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       \n",
            "\t\t\t\t\t\t\t\n",
            "     \n",
            "\t\t\t\t\t\t\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qng8IlRG5-00"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rjwgu0qgbpd"
      },
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "130LetV1RACp"
      },
      "source": [
        "\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(x_train), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(x_train), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(x_train), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1LKPyt3RJeP"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(x_train, y_train)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1klOilmmhl4"
      },
      "source": [
        "encoder_input_val = np.zeros(\n",
        "    (len(x_val), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_val = np.zeros(\n",
        "    (len(x_val), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_val = np.zeros(\n",
        "    (len(x_val), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C60oiTim1TQ"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(x_val, y_val)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_val[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_val[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_val[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_val[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_val[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_val[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8mOmLdH64v0"
      },
      "source": [
        "encoder_input_test = np.zeros(\n",
        "    (len(x_test), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_test = np.zeros(\n",
        "    (len(x_test), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_test = np.zeros(\n",
        "    (len(x_test), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al12TtdC7Zun"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(x_test, y_test)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_test[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_test[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_test[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_test[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_test[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_test[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KOetQTjymcF",
        "outputId": "21dbbbc8-93a6-4e33-9d33-e58625bafceb"
      },
      "source": [
        "encoder_input_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13260, 20, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzj-spBru8IY"
      },
      "source": [
        "# Configure the sweep – specify the parameters to search through, the search strategy, the optimization metric et all.\n",
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'values':[1]\n",
        "            # 'values': [5,7,9, 10,11]\n",
        "            # 'values':[100,50]\n",
        "        },\n",
        "        'weight_decay':{\n",
        "           #'values': [0, 1e-1, 1e-2, 1e-3,0.00099,0.00111]\n",
        "            'values':[1e-3]\n",
        "          #  'values':[0.00099]\n",
        "        },\n",
        "         'batchSize':{\n",
        "            'values':[16,32,64]\n",
        "            # 'values':[8]\n",
        "            # 'values':[16]\n",
        "        },\n",
        "        'regular_dropout':{\n",
        "            #'values':[0.2,0.3,0.4]\n",
        "             'values':[0.2]\n",
        "            # 'values':[0.4]\n",
        "        },\n",
        "        'recurrent_dropout':{\n",
        "            #'values':[0.2,0.3,0.4]\n",
        "             'values':[0.2]\n",
        "            # 'values':[0.2]\n",
        "        },\n",
        "        'regular_activation':{\n",
        "            'values': ['sigmoid','tanh','relu']\n",
        "            #  'values':['sigmoid']\n",
        "            # 'values':['relu']\n",
        "        },\n",
        "        'recurrent_activation':{\n",
        "            'values': ['sigmoid','tanh','relu']\n",
        "            # 'values':['relu']\n",
        "            #  'values':['sigmoid']\n",
        "        },\n",
        "        'no_of_hidden_layers':{\n",
        "            'values':[1,2,3]\n",
        "            # 'values':[2]\n",
        "            # 'values':[3]\n",
        "        },\n",
        "        'hidden_layers_size':{\n",
        "            'values':[64,128,256]\n",
        "            # 'values':[256]\n",
        "            # 'values':[128]\n",
        "            # 'values':[16]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':['RNN','GRU','LSTM']\n",
        "            # 'values':['LSTM']\n",
        "            # 'values':['GRU']\n",
        "        }\n",
        "        # 'train_word_accuracy':{\n",
        "        #     'values':[0]\n",
        "        # }\n",
        "        # 'input_embedding_size':{\n",
        "        #     'values':[16,32,64,256]\n",
        "        # } \n",
        "        \n",
        "        #'activation': {\n",
        "            # 'values': ['relu', 'elu', 'selu', 'softmax']\n",
        "         #   'values': ['sigmoid','tanh','ReLu']\n",
        "        #}\n",
        "        \n",
        "        \n",
        "    }\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "mH418DvWv1XX",
        "outputId": "22a48e93-6ba6-414c-d28c-5948b4c0eaa2"
      },
      "source": [
        "  sweep_id = wandb.sweep(sweep_config, entity=\"dl_45_47\", project=\"Transliteration_model\")\n",
        "  #d7f2d3b3afd25dff68841ada514c88e687894723"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 2cp889xc\n",
            "Sweep URL: https://wandb.ai/dl_45_47/Transliteration_model/sweeps/2cp889xc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ_LnCxy4JJ_"
      },
      "source": [
        "**REAL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTSGllLk9T2D"
      },
      "source": [
        "def RNN_model(config):\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "  encoder_inputs_1 = encoder_inputs\n",
        "  encoder_states_1 = []\n",
        "  for i in range(config.no_of_hidden_layers-1):\n",
        "    encoder_inputs_1, state_1 = (SimpleRNN(config.hidden_layers_size, return_sequences=True,return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation))(encoder_inputs_1)\n",
        "    encoder_states_1.append(state_1)\n",
        "  encoder_inputs_1, state_1 = (SimpleRNN(config.hidden_layers_size, return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation))(encoder_inputs_1)\n",
        "  encoder_states_1.append(state_1)\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "  decoder_inputs_1 = decoder_inputs\n",
        "  for i in range(config.no_of_hidden_layers):\n",
        "    decoder_inputs_1, _ = (SimpleRNN(config.hidden_layers_size, return_sequences=True,return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation))(decoder_inputs_1, initial_state=encoder_states_1[i])\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax', kernel_regularizer=regularizers.l2(config.weight_decay))\n",
        "  decoder_outputs = (decoder_dense)(decoder_inputs_1)\n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzIk0yd5yKG2"
      },
      "source": [
        "def LSTM_model(config):\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "  encoder_inputs_1 = encoder_inputs\n",
        "  encoder_states_1 = []\n",
        "  for i in range(config.no_of_hidden_layers-1):\n",
        "    encoder_inputs_1, state_h_1, state_c_1 = (LSTM(config.hidden_layers_size, return_sequences=True,return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation, recurrent_activation=config.recurrent_activation))(encoder_inputs_1)\n",
        "    encoder_state = [state_h_1, state_c_1]\n",
        "    encoder_states_1.append(encoder_state)\n",
        "  encoder_inputs_1, state_h_1, state_c_1 = (LSTM(config.hidden_layers_size, return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation, recurrent_activation=config.recurrent_activation))(encoder_inputs_1)\n",
        "  encoder_state = [state_h_1, state_c_1]\n",
        "  encoder_states_1.append(encoder_state)\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "  decoder_inputs_1 = decoder_inputs\n",
        "  for i in range(config.no_of_hidden_layers):\n",
        "    decoder_inputs_1, _, _ = (LSTM(config.hidden_layers_size, return_sequences=True,return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation, recurrent_activation=config.recurrent_activation))(decoder_inputs_1, initial_state=encoder_states_1[i])\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax', kernel_regularizer=regularizers.l2(config.weight_decay))\n",
        "  decoder_outputs = decoder_dense(decoder_inputs_1)\n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flw3XWqY-E4S"
      },
      "source": [
        "def GRU_model(config):\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "  encoder_inputs_1 = encoder_inputs\n",
        "  encoder_states_1 = []\n",
        "  for i in range(config.no_of_hidden_layers-1):\n",
        "    encoder_inputs_1, state_1 = (GRU(config.hidden_layers_size, return_sequences=True,return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation))(encoder_inputs_1)\n",
        "    encoder_states_1.append(state_1)\n",
        "  encoder_inputs_1, state_1 = (GRU(config.hidden_layers_size, return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation))(encoder_inputs_1)\n",
        "  encoder_states_1.append(state_1)\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "  decoder_inputs_1 = decoder_inputs\n",
        "  for i in range(config.no_of_hidden_layers):\n",
        "    decoder_inputs_1, _ = (GRU(config.hidden_layers_size, return_sequences=True,return_state=True,dropout=config.regular_dropout, recurrent_dropout=config.recurrent_dropout,activation=config.regular_activation))(decoder_inputs_1, initial_state=encoder_states_1[i])\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax', kernel_regularizer=regularizers.l2(config.weight_decay))\n",
        "  decoder_outputs = decoder_dense(decoder_inputs_1)\n",
        "\n",
        "   # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwqb9kkPwBeU"
      },
      "source": [
        "# The sweep calls this function with each set of hyperparameters\n",
        "def train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  #\n",
        "\n",
        "    config_defaults = {\n",
        "        'epochs': 5,\n",
        "        'weight_decay': 1e-2,\n",
        "         'batchSize':16,\n",
        "        'regular_dropout':0.2,\n",
        "        'recurrent_dropout':0.2,\n",
        "        'no_of_hidden_layers':1,\n",
        "        'hidden_layers_size':256,\n",
        "        'cell_type':'LSTM'\n",
        "    }\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults)\n",
        "    \n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    if config.cell_type == 'RNN':\n",
        "      model = RNN_model(config)\n",
        "    elif config.cell_type == 'LSTM':\n",
        "      model = LSTM_model(config)\n",
        "    elif config.cell_type == 'GRU':\n",
        "      model = GRU_model(config)\n",
        "    \n",
        "    # plot_model(encoder_model, to_file='encoder_model.png', show_shapes=True)\n",
        "    # plot_model(decoder_model, to_file='decoder_model.png', show_shapes=True)\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit([encoder_input_data, decoder_input_data],decoder_target_data, epochs=config.epochs,validation_data=([encoder_input_val, decoder_input_val],decoder_target_val), batch_size=config.batchSize) \n",
        "\n",
        "    accuracy, loss, val_accuracy, val_loss = history.history['accuracy'], history.history['loss'], history.history['val_accuracy'], history.history['val_loss']\n",
        "\n",
        "    # wandb.log({'val_loss' : val_loss, 'val_accuracy': val_accuracy})\n",
        "\n",
        "    for i in range(config.epochs):\n",
        "      wandb.log({'val_loss' : val_loss[i], 'val_accuracy': val_accuracy[i],'loss' : loss[i], 'accuracy': accuracy[i], 'epoch': i})\n",
        "    \n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "db4a6d72dc0449df9f66d9626b44d8cc",
            "2a29ee2f4e884222a45c2e4a85d88d82",
            "29ddde6b6cc84fbd86f773ca360c7e1b",
            "a0794163c0ba4a32b451c3856b2d4b02",
            "177a1addc5a2420d8a1f89c87e592bf0",
            "10ff7cf84c3345f79ef443d7408822f2",
            "b1b7e00b772e456c9ffb8f3214ff67a3",
            "89e2e6a117004e719048d1706764abc3"
          ]
        },
        "id": "oHh8tVDn6wXa",
        "outputId": "a68eaa09-a901-4492-e25a-a4775cb2ed2c"
      },
      "source": [
        "# 18 May\n",
        "wandb.agent(sweep_id, train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1tx5e1xh with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_hidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_activation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregular_activation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregular_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdl_45_47\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">cool-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model/sweeps/2cp889xc\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model/sweeps/2cp889xc</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model/runs/1tx5e1xh\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model/runs/1tx5e1xh</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210526_081710-1tx5e1xh</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1741/1741 [==============================] - 328s 160ms/step - loss: 1.3155 - accuracy: 0.7030 - val_loss: 0.9465 - val_accuracy: 0.7490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 331<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db4a6d72dc0449df9f66d9626b44d8cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210526_081710-1tx5e1xh/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210526_081710-1tx5e1xh/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>val_loss</td><td>0.94652</td></tr><tr><td>val_accuracy</td><td>0.74904</td></tr><tr><td>loss</td><td>1.0951</td></tr><tr><td>accuracy</td><td>0.72663</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>_runtime</td><td>376</td></tr><tr><td>_timestamp</td><td>1622017406</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>val_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">cool-sweep-1</strong>: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model/runs/1tx5e1xh\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model/runs/1tx5e1xh</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sihxvy2w with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_hidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_activation: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregular_activation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregular_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">stellar-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model/sweeps/2cp889xc\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model/sweeps/2cp889xc</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/dl_45_47/Transliteration_model/runs/sihxvy2w\" target=\"_blank\">https://wandb.ai/dl_45_47/Transliteration_model/runs/sihxvy2w</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210526_082331-sihxvy2w</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYnxgDvHkxd0"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}